{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "932138ef-8833-4d05-b088-e273355ccae5",
   "metadata": {},
   "source": [
    "## Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472758c-deff-461f-8a23-6704f697879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polynomial functions and kernel functions are related in the context of machine learning, particularly in support vector machines (SVMs) \n",
    "and kernel methods. Kernel functions are a generalization of polynomial functions, and they play a crucial role in transforming data into \n",
    "higher-dimensional spaces, making it possible to learn complex relationships between features.\n",
    "\n",
    "Here's the relationship between polynomial functions and kernel functions:\n",
    "\n",
    "Polynomial Functions: \n",
    "    A polynomial function is a mathematical function of the form:\n",
    "\n",
    "    f(x) = a_n * x^n + a_(n-1) * x^(n-1) + ... + a_2 * x^2 + a_1 * x + a_0\n",
    "\n",
    "    In the context of machine learning, polynomial functions are often used for feature transformation. For example, in polynomial regression, \n",
    "    you can transform your input features using polynomial functions to capture non-linear relationships between variables.\n",
    "\n",
    "Kernel Functions: \n",
    "    Kernel functions are used in kernel methods, such as kernelized SVMs and kernelized regression. These functions are a generalization of \n",
    "    polynomial functions and can be polynomial kernels or more complex functions.\n",
    "\n",
    "    Polynomial Kernel: \n",
    "        A polynomial kernel is a specific type of kernel function that computes the similarity between data points in a higher-dimensional space\n",
    "        using a polynomial function. \n",
    "        The polynomial kernel of degree \"d\" between two vectors x and y is defined as:\n",
    "\n",
    "        K(x, y) = (x · y + c)^d\n",
    "\n",
    "        Here, \"c\" is a constant and \"d\" is the degree of the polynomial. This kernel function implicitly performs a polynomial feature\n",
    "        transformationwithout explicitly calculating the transformed feature vectors. It allows SVMs to learn non-linear decision boundaries.\n",
    "\n",
    "    Other Kernel Functions: \n",
    "        Besides polynomial kernels, there are various other kernel functions, such as the radial basis function (RBF) kernel and sigmoid kernel. \n",
    "        These kernels can capture even more complex relationships between data points in higher-dimensional spaces.\n",
    "\n",
    "The relationship between polynomial functions and kernel functions lies in the fact that kernel functions, including polynomial kernels, are used\n",
    "to perform non-linear transformations of data points into higher-dimensional spaces. This transformation helps machine learning algorithms like \n",
    "SVMs to find decision boundaries that would be difficult to express using linear functions alone. Polynomial kernels are a specific type of kernel\n",
    "function that employs polynomial functions to achieve this transformation, but kernel methods allow for greater flexibility with different kernel \n",
    "choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e102cf4-c500-423f-a483-577c5f49bda7",
   "metadata": {},
   "source": [
    "## Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c859e360-0ea7-4e0d-ba31-25e6bf377482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SVM model with polynomial kernel: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset (Iris dataset as an example)\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # Selecting the first two features (sepal length and sepal width)\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into a training set and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate an SVM classifier with a polynomial kernel\n",
    "# The 'C' parameter controls the regularization strength\n",
    "svm_classifier = SVC(kernel='poly', degree=3, C=1.0)  # Example: 3rd-degree polynomial kernel\n",
    "\n",
    "# Train the SVM classifier on the training set\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the model on the testing set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the SVM model with polynomial kernel: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ee786-1f74-4762-a2ac-d5bda47a5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this example:\n",
    "\n",
    "    1. We load the Iris dataset (you can replace it with your dataset).\n",
    "    2. We split the data into a training set and a testing set using train_test_split.\n",
    "    3. We instantiate an SVM classifier with a polynomial kernel using the SVC class. You can specify the degree of the polynomial using the degree\n",
    "        parameter (e.g., degree=3 for a cubic polynomial).\n",
    "    4. We train the SVM classifier on the training set using fit.\n",
    "    5. We predict the labels for the testing set using predict.\n",
    "    6. Finally, we compute and print the accuracy of the model on the testing set.\n",
    "    \n",
    "You can adjust the parameters like the degree of the polynomial and the regularization strength (C) to fine-tune the model for your specific \n",
    "problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df47d3-8b0f-4a07-a898-d90181f239c0",
   "metadata": {},
   "source": [
    "## Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d552ac1c-2dcd-4738-a8dc-2aeda2656ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "In Support Vector Regression (SVR), epsilon (ε) represents the margin of tolerance around the predicted value within which no penalty is\n",
    "associated in the loss function. It plays a crucial role in determining the number of support vectors and, consequently, the flexibility of the \n",
    "SVR model.\n",
    "\n",
    "Here's how increasing the value of epsilon affects the number of support vectors in SVR:\n",
    "\n",
    "Smaller Epsilon (Tight Margin): \n",
    "    When you have a smaller epsilon, the margin around the predicted value becomes tight. This means that the SVR model is more sensitive to data \n",
    "    points that are relatively closer to the predicted value. As a result:\n",
    "\n",
    "    Fewer data points become support vectors because the model can achieve a good fit by considering only the data points that are very close to\n",
    "    the predicted value.\n",
    "    The model may become less flexible and may not capture certain patterns or outliers in the data.\n",
    "\n",
    "Larger Epsilon (Wide Margin): \n",
    "    Conversely, when you increase the value of epsilon, you widen the margin around the predicted value. This means that the SVR model allows more\n",
    "    data points to be within the margin without incurring a penalty. As a result:\n",
    "\n",
    "    More data points may become support vectors because the model tolerates a larger range of errors.\n",
    "    The model becomes more flexible and is more likely to capture a broader range of patterns in the data, including outliers.\n",
    "\n",
    "In summary, increasing the value of epsilon in SVR tends to increase the number of support vectors. A smaller epsilon leads to a tighter margin\n",
    "and fewer support vectors, while a larger epsilon leads to a wider margin and more support vectors. The choice of epsilon should be made carefully\n",
    "based on the specific characteristics of your data and the desired trade-off between model flexibility and robustness to errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3036bf-43df-4489-b145-e4e114197e54",
   "metadata": {},
   "source": [
    "## Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de2166-3ae0-4b0f-8440-0792f36effbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Support Vector Regression (SVR) is a powerful regression technique, and the choice of its parameters significantly affects its performance. \n",
    "Here, we'll discuss how the choice of kernel function, C parameter, epsilon parameter (ε), and gamma parameter (γ) influences SVR's performance,\n",
    "along with examples of when to increase or decrease each parameter.\n",
    "\n",
    "Kernel Function:\n",
    "\n",
    "    Function: The kernel function defines the transformation of input features into a higher-dimensional space, allowing SVR to model non-linear \n",
    "    relationships.\n",
    "    Effect: The choice of kernel function determines the model's capacity to capture complex patterns.\n",
    "    Examples:\n",
    "        Linear kernel (default): Use when you assume a linear relationship between features.\n",
    "        RBF kernel: Effective for non-linear relationships. Increase if data is highly non-linear.\n",
    "        Polynomial kernel: Suitable for polynomial relationships. Adjust the degree parameter.\n",
    "        Sigmoid kernel: Useful for sigmoid-shaped data. Modify the coef0 parameter.\n",
    "\n",
    "C Parameter (Regularization):\n",
    "\n",
    "    Function: The C parameter controls the trade-off between model simplicity and accuracy. Smaller values encourage a simpler model, while larger\n",
    "    values prioritize accuracy.\n",
    "    Effect: High C values make SVR more sensitive to individual data points, potentially overfitting. Low C values introduce regularization and make\n",
    "    the model more robust.\n",
    "    Examples:\n",
    "        Increase C for better fit when the training data is reliable.\n",
    "        Decrease C when you suspect noise or outliers in the data.\n",
    "\n",
    "Epsilon Parameter (ε):\n",
    "\n",
    "    Function: Epsilon defines the margin within which errors are tolerated. It determines the width of the ε-insensitive tube around the predicted \n",
    "    values.\n",
    "    Effect: Smaller ε values create a narrow margin and enforce precise fitting, potentially increasing sensitivity to noise. Larger ε values \n",
    "    introduce flexibility and tolerate larger errors.\n",
    "    Examples:\n",
    "        Decrease ε for precise prediction when the data is noise-free.\n",
    "        Increase ε for robustness against noisy data.\n",
    "\n",
    "Gamma Parameter (γ):\n",
    "\n",
    "    Function: The gamma parameter affects the shape and flexibility of the kernel function, particularly in RBF and polynomial kernels.\n",
    "    Effect: High γ values make the model sensitive to nearby points, leading to complex, wiggly decision boundaries (risk of overfitting). Low γ \n",
    "    values result in smoother decision boundaries (risk of underfitting).\n",
    "    Examples:\n",
    "        Increase γ when the data is highly non-linear or has fine-grained patterns.\n",
    "        Decrease γ when the data is relatively smooth or has large-scale patterns.\n",
    "\n",
    "In practice, it's essential to perform hyperparameter tuning, often using techniques like grid search or randomized search, to find the optimal \n",
    "combination of kernel, C, ε, and γ for your specific dataset. The choice of these parameters should be guided by your understanding of the data and \n",
    "the trade-offs between model complexity, generalization, and robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c6cd0a-5579-490e-b462-0368efc66dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Assignment:\n",
    "    Import the necessary libraries and load the dataset\n",
    "    Split the dataset into training and testing set\n",
    "    Preprocess the data using any technique of your choice (e.g. scaling, normalization)\n",
    "    Create an instance of the SVC classifier and train it on the training data\n",
    "    Use the trained classifier to predict the labels of the testing data\n",
    "    Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,precision, recall, F1-score)\n",
    "    Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performance\n",
    "    Train the tuned classifier on the entire dataset\n",
    "    Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c50991-bd48-4c76-865b-1f5217211b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and load the dataset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "data=load_iris()\n",
    "X=data.data\n",
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d6360c-275b-4afa-915b-a94b58840b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing set\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd0f220-9cad-4595-b25d-c6d22f44d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data using any technique of your choice (e.g. scaling, normalization)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8041857d-fb77-4134-a9e2-472748c4bd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the SVC classifier and train it on the training data\n",
    "\n",
    "svc=SVC(kernel='rbf',C=0.1)\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90ec5bf1-1d0f-41d0-980d-c651b0310aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained classifier to predict the labels of the testing data\n",
    "\n",
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d7e89d-cc66-4151-b05d-8d98685d87ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SVC model without hypertuning is 0.9\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-score)\n",
    "\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "print(f\"Accuracy of the SVC model without hypertuning is\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8a68b8-beed-4f43-bfc6-0d43a8923789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [0.01, 0.1, 1],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [0.01, 0.1, 1],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1],\n",
       "                         'kernel': ['linear', 'rbf']})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performance\n",
    "\n",
    "parameters={'C':[0.1,1,10],'kernel':['linear','rbf'],'gamma':[0.01,0.1,1]}\n",
    "grid_search=GridSearchCV(SVC(),parameters,cv=5)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8641a5-5002-4977-b80a-595bbaebcc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.01, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac4bb258-80f7-4ed4-8905-50c39a2f638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SVC model with hypertuning is 0.96\n"
     ]
    }
   ],
   "source": [
    "# Train the tuned classifier on the entire dataset\n",
    "\n",
    "tuned_svc=SVC(kernel='linear',C=1.0,gamma=0.01)\n",
    "tuned_svc.fit(X_train,y_train)\n",
    "y_tuned_pred=tuned_svc.predict(X_test)\n",
    "\n",
    "tuned_accuracy=accuracy_score(y_test,y_tuned_pred)\n",
    "print(f\"Accuracy of the SVC model with hypertuning is\",tuned_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73d2ed3-839d-4de5-a5c0-23af2544ee64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tuned_svc.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained classifier to a file for future use.\n",
    "\n",
    "joblib.dump(tuned_svc,'tuned_svc.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
